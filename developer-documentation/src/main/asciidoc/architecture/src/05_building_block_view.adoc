[[section-building-block-view]]
== Building Block View

=== Whitebox Overall System

.Whitebox overall system
[plantuml,qalipsis-whitebox-overall-system,png]
----
skinparam componentStyle uml2

interface "external systems" as external
interface "Monitoring" as monitoring
actor Tester as tester
component "CI/CD-Tool" as ci
component "Reporting-Tool" as reporting

rectangle "Qalipsis" as qalipsis {
  interface "HTTP API / Website" as http

  component "Head(s)" as head
  component "Factory(s)" as factory
  component "Proxy" as proxy

  database Configuration as config
  database "Time-Series storage" as ts
  storage "Cache" as cache
  file "Test results" as results
  queue "Messaging\nplatform" as messaging_platform

  http -down-> head

  head <-> messaging_platform
  head <-down-> ts
  head <-down- config
  head <-down- results
  messaging_platform <-> factory
  factory <-down-> cache
  factory <-down-> external
  factory <-right-> proxy
  proxy <-down-> external
  proxy -left-> messaging_platform
  proxy -down-> cache
}

tester -down-> http
ci -down-> http
reporting -up-> ts
qalipsis -down-> monitoring

----

==== Motivation

Qalipsis addresses a lot of problematics of the distributed systems and we used functional decomposition to split the responsibilities and design the relevant components.

==== Contained Building Blocks

===== Head (Blackbox)

Responsibility::
- Orchestrates all the factories to execute load test scenarios.
- Assign a sub-part of the directed acyclic graph of a scenario and minions to the Factories.
- Provides a cockpit GUI to pilot the executions.
- Provides a reporting GUI to visualize results.
- Provides a REST interface to trigger, configure the executions and extract results.
- Consumes the metrics and results from the messaging platform and persists them in the time-series storage.
- Performs ans persists configurable aggregations in the consumed data, in order to make reporting faster.


Performance::
Reactivity of the GUI is a key.
It should be developed as a single application page and only refreshes the required data.
Running several heads behind a load-balancer might help to scale the number of users.
Since the data transport relies on messaging, there is no need for a head to head synchronization.

Form::
A head can be deployed in two forms: as a separated isolated service running in its own Java Virtual Machine or embedded, alongside with one instance of factory.

===== Factory(s) (Blackbox)

Responsibility::
- Parses each scenario to convert it into a directed acyclic graph and extract its sub-parts having the same execution selectors (see below for more details)
- Executes the assigned sub-part of the directed acyclic graph toward the assigned minions.
- Executes actions onto the target system.
- Fetches data from the target system in order to run either further actions or assertions.
- Calculate metrics and distribute them onto the messaging platform.

Performance::
Key feature of a Factory is to be able to simulate a very high load with as less physical resources as possible.
Thus, light threads, non-blocking programming are strongly recommended.

Form::
A Factory can be deployed in two forms: as a separated isolated service running in its own Java Virtual Machine or embedded, alongside with one a head.

Problems::
The main problem of the distributed factories concerns the partition of data and the optimization of data transfer which only concern one minion among all the factories.
The aspect will be discussed in detail below, when the partitioning component will be described.

===== Proxy (Blackbox)

Responsibility::
It is considered as an instrumentation tool installed within the tested platform in order to increase the grip of Qalipsis on the tested systems:
- Provides a man-in-the-middle interceptor for the plug-ins supported by Qalipsis, in order to keep track of the information transferred in the target system and make them available for Qalipsis with a (not too) big impact of the system performances.
- Shares the captured data in the messaging platform or in the cache.
- Interprets the requests and responses when relevant in order to allow the address or port translation when the observed protocol does not support it natively.

Performance::
The capture of messages should not significantly affect the latency of the tested platform.
Introduced latency should not exceed 10 Âµs (microseconds) in the worst case.

Form::
It is a separated service, running with a technology supporting native packaging for the targeted operating systems.
Linux, Windows and MacOS (all in 64 bits) will have the priority.

Risks::
The risk of affecting the performances of the instrumented system is important.
The proxy will have to be massively load-tested.

===== Time-Series storage (Blackbox)

Responsibility::
- Stores time-based data

Performance::
It should support a very high ingestion throughput to face the massive amount of generated metrics and results.

Form::
* When using the standalone deployment, https://github.com/Netflix/atlas[Atlas] is used since it works in-memory
* When using the distributed deployment, several solutions are supported, in order to make the interfacing with analysis tools possible and easier:
** https://www.elastic.co[Elasticsearch], which also comes with the reporting GUI https://www.elastic.co/products/kibana[Kibana] to provide advanced analysis capability
** https://www.influxdata.com/products/influxdb-overview/[InfluxDB], which can be connected to Grafana

Further systems might be supported in the future to better integrate Qalipsis into the existing IT landscapes.

===== Cache (Blackbox)

Responsibility::
- Stores ephemeral data to be used for actions and assertions.
- Stores information accessible to all the factories.

Performance::
The cache shall provide a very high throughput and very low latency to avoid discarding Qalipsis as a load test platform.

Form::
* When using the standalone deployment, the cache is provided by https://github.com/ben-manes/caffeine[Caffeine], wwhich we consider the fastest cache implementation on the Java Virtual Machine.
* When using the distributed deployment, the cache is provided by http://redis.io[Redis], either a single server or a cluster (strongly recommended for mid to high load).

===== Messaging platform (Blackbox)

Responsibility::
- Distributes data from heads to factories.
- Distributes data from factories to heads.
- Distributes data between factories.
- Distributes data from Factories to time-series factories.

Form::
* When using the standalone deployment, Kotlin channels are used.
* When using the distributed deployment, either http://redis.io[Redis] (for low to medium load) or https://kafka.apache.org[Apache Kafka] are supported, which requires more effort to operate but better suits to Cloud infrastructures.

===== Other Qalipsis building blocks

.Other Qalipsis building blocks
[options="header",cols="1,4"]
|===
| Name | Responsibility
| Configuration | Persisted parameters for execution and administration are kept in a RDBMS. Only the heads are allowed to read it and share the information to the factories using messages. By default for the standalone deployment, H2 is used and persisted. In the other cases, PostgreSQL is supported. In all cases, https://r2dbc.io[Reactive connectors] are used.
| Test results | For compatibility purpose, XUnit-like files can be generated by the heads to integrate the results into existing tools (CI/CD platforms...)
|===

==== Important Interfaces

.Important interfaces of Qalipsis
[options="",cols="1,4"]
|===
| External systems | Qalipsis factories are in charge of executing the load test scenarios, which consist of actions performed on external systems and assertions based upon on data those systems also provide.
| Reporting tool | Qalipsis provides reporting capabilities to analyze the results and drill-down to the details. However, one might prefer to use other dedicated tools able to interface with the time-series platforms supported by Qalipsis.
| CI/CD tool | Qalipsis is used in a context of quality validation of software and is very keen on being triggered by third-parties CI tools to integrate it into a continuous integration / delivery / deployment pipeline.
| Monitoring | As a load-test tool, Qalipsis is an intensive user of CPU, memory and network resources and is required to be monitored for mid to large-scale deployments, in order to verify that the expected load can be generated on the target system.
|===

=== Level 2

==== Factory (Whitebox)

.Whitebox Factory
[plantuml,qalipsis-whitebox-factory-factory,png]
----
skinparam componentStyle uml2

queue "Head\ndirectives" as head_directives
queue "Heartbeat\nFeedback" as feedback_to_head
queue "Shared\nmetadata" as data_queues
queue "Metrics" as metrics_queues
storage "Data cache" as cache
storage "Directives cache" as directive_cache

component "Head" as head

head -down-> head_directives
head <-down- feedback_to_head
head -> directive_cache

package "Factory" as factory {
  boundary "Head directive\nconsumer" as directives_consumer
  boundary "Shared data\nconsumer" as data_consumer
  agent "Orchestration" as orchestration
  interface "Cross\nfactory\nproxy" as cross_factory_proxy
  component "Correlation\nprocessor" as correlation_processor
  interface "Status\nReporter" as status_reporter
  actor "Minions" as minions
  interface "Metrics\nReporter" as metrics_reporter
  queue "Data channels" as data_channels
  storage "Minions\nregistry" as minions_registry

  head_directives -down-> directives_consumer
  directives_consumer -down-> orchestration
  orchestration .down.* minions
  orchestration -left-> status_reporter
  orchestration .> directive_cache
  orchestration .> minions_registry
  status_reporter -up-> feedback_to_head
  cross_factory_proxy -up-> data_queues
  data_queues -up-> data_consumer
  data_consumer -up-> correlation_processor
  metrics_reporter -down-> metrics_queues
  minions -* data_channels
  data_channels <- correlation_processor
  correlation_processor .down.> cache
  correlation_processor .> cross_factory_proxy
  correlation_processor .up.> minions_registry
  minions .down.> cross_factory_proxy
  cross_factory_proxy -down-> cache
  minions .down.> metrics_reporter
}

----

Orchestration::
Responsibility:::
The Orchestration module is in charge of executing the scenarios steps for the minions assigned to the relevant Factory.
It pilots the execution of the minions, scenarios and steps altogether.
+
It registers the factory to the head at startup and analyzes the scenarios.
+
It receives the directives from the head and applies them: creates, starts, pauses, resumes and stops minions.
+
It provides status updates to the Status Reporter.
+
When the directive received from the head is of nature "burn after reading", it actually only contains a key in the cache.
The runner will then try to fetch the value with the key if it still exists and will apply the described directive.
This strategy allows sending a directive to a set of factories, being sure that only the fastest will run it.
+
The runner is a singleton for each factory.

Minions registry::
Responsibility:::
Keeps the list of minions with their details and states.
Basically, a storage of minions with their UUID as key.

Status reporter::
Responsibility:::
Forward the last status updates to the messaging platform to make them visible to the heads.
If one factory is no longer active, the head might decide to make it stop and rebalance its minions or ask the user for a decision using the GUI.
+
Its concrete implementation depends on the running messaging technology.
+
The status reporter is a singleton for each factory.

Minion::
Responsibility:::
The actor simulating each piece of IoT device, each user or each system generating load to the target system.
There might a lot of them in a factory if its has to simulate a lot of users / devices / systems.
When a minion expects an incoming data from another component, it will provide it one or several channels, in which the items have to be pushed.

Performance:::
Due to the massive number of minions in a factory (potentially hundreds of thousands, or even millions), they will be implemented using coroutines instead of threads.
This will make their idle period totally invisible for the consumption of resources (CPU, Memory).

Correlation processor::
Responsibility:::
It is in charge of distributing the data to the right step of the right minion at the right moment, keeping the so-far-received-but-still-incomplete sets of data in cache.
When data to be dispatched does no belong to the current factory, the correlation processor forwards it the cross factory proxy.
+
When metadata of shared item is received from the "Shared metadata queues", if the correlation processor knows a data channel with same key, the value is fetched from the cache.
+
The correlation processor is a singleton for each factory.

Cross factory proxy::
Responsibility:::
It pushes the received data to the distributed cache and pushes its metadata to the queue(s) related to the next step(s) in the scenario.
+
Its concrete implementation depends on the running messaging technology.
+
The cross factory proxy is a singleton for each factory.


Metrics reporter::
Responsibility:::
It asynchronously pushes the metrics to the messaging platform.
+
Its concrete implementation depends on the running messaging technology and uses batches as big as possible to reduce the transport overhead.
+
The metrics reporter is a singleton for each factory.

==== Head (Whitebox)

.Whitebox Head
[plantuml,qalipsis-whitebox-head,png]
----
skinparam componentStyle uml2

queue "Head\ndirectives" as head_directives
queue "Heartbeat\nFeedback" as feedback_to_head
queue "Metrics" as metrics
storage "Directives cache" as directive_cache
database "Configuration" as config
database "Time series" as time_series

package "Head" as head {
  interface "Directives\nproducer" as directives_producer
  boundary "Heartbeat\nFeedback\nconsumer" as heartbeat_consumer
  boundary "Metrics\nconsumer" as metrics_consumer
  frame "Testing GUI" as test_gui
  frame "Administration GUI" as administration_gui
  component "Reporting\nAPI" as reporting_api
  component "Testing\nAPI" as test_api
  component "Administration\nAPI" as administration_api
  component "Factories\nAPI" as factories_api

  feedback_to_head -down-> heartbeat_consumer
  metrics -down-> metrics_consumer

  test_gui .down.> test_api
  test_api .down.> directives_producer
  test_api -down-> config
  test_gui .> factories_api

  factories_api .down.> heartbeat_consumer
  factories_api .down.> directives_producer

  metrics_consumer <.down. reporting_api
  test_gui .down-> reporting_api
  reporting_api -down-> time_series

  directives_producer -down-> directive_cache
  directives_producer -down-> head_directives

  administration_gui .down-> administration_api
  administration_api -down-> config
}

actor Tester as tester
actor Operations as operations

tester .down.> test_gui
operations .down.> administration_gui

----

Testing GUI::
Responsibility:::
Provides a graphical access to the testing API and factories API.

Testing API::
Responsibility:::
Provides all actions to drive a test campaign and visualize its current state, as well as results from past and current test campaigns.

Open issues:::
It might be later required to split the API, in order to cover the increasing scope of features while keeping things as single-responsible.

Factories API::
Responsibility:::
Provides all actions to manage the states of the factories.

Reporting API::
Responsibility:::
Provides all actions to persist the metrics and report the results of past and current test campaigns.

Administration API::
Responsibility:::
Provides all actions to manage structural configuration of Qalipsis.

Directives producer::
Responsibility:::
Component in charge of forwarding directives to the relevant factories via the messaging platform.

Heartbeat & Feedback consumer::
Responsibility:::
Consumes the state and pulse messages coming from the factories via the messaging platform to provide them to the factories API.

Metrics consumer::
Responsibility:::
Consumes the metrics coming from all the factories to push them into the reporting API in order to persist them into the time-series database.

=== Level 3

==== Factory - Orchestration (Whitebox)

.Whitebox Factory - Orchestration
[plantuml,qalipsis-whitebox-factory-orchestration,png]
----
skinparam componentStyle uml2


package "Head directive consumer" {
    DirectiveConsumer "1" -left-> "1" DirectiveCacheReader: pops\ndirective >
}

DirectiveConsumer "1" -down-> "1" Runner: do >

Runner "1" *-down- "*" Minion
Runner "1" ..> "*" Minion: creates,\npauses\nresumes and\ndestroys >
Runner "1" -right-> MinionsRegistry: maintains >
Runner "1" -left-> ScenariosKeeper: analyzes >

Runner -down-> HeadNotifier: pushes\nupdates >
ScenariosKeeper -> HeadNotifier: pushes\n >

----

DirectiveConsumer::
The DirectiveConsumer is a consumer of the messages coming from the head and forwards them to the relevant component of the factory: Runner or ScenariosKeeper.

DirectiveCacheReader::
When the received directive is relevant for the factory but not is only a reference to an entry in the directive cache, the DirectiveConsumer asks the DirectiveCacheReader to pop the actual directive from the distributed directive cache, using the provided key.
If the directive was already popped by another factory, it is just ignored.

ScenariosKeeper::
The ScenariosKeeper is composed of a registry to keep the full description of all the scenarios supported by the factory as well as an analyzer in charge of decomposing the scenarios when it receives a directive for it from the head.
The decomposition of the scenario (requested from the head as a reference to a directive) is then shared to all the factories via messaging and kept in each registry.

Minion::
A Minion is an actor entity, which simulates exactly one user, device or external system by running the steps of the scenario that can be executed on the factory (See the concept of selectors below).
A Minion is identified by an ID, which is actually a trace ID in the sense of distributing tracing requirements.
Each step it performs opens and closes a new span.
For technical reasons, a minion can run in parallel or consecutively on different factories.

MinionsRegistry::
The MinionsRegistry keeps a reference on all the existing minions accessible by their ID.
It helps to find a minion easily when when it is clearly identified as the target of an incoming message.
The MinionsRegistry also provides utility functions to find the Minions in a given state in order to support the Runner operations.

Runner::
The Runner is the masterpiece of the factory and drives the minions to execute directed acyclic graphs (aka DAGs) as requested by the head.
It creates the Minions and assign them a list of DAGs, which are not directly connected altogether.
The DAGs generally have input and output which are connected via messaging to the other DAGs of the same minions running on different factories.

==== Factory - Scenarios (Whitebox)

.Whitebox Factory - Executing scenarios
[plantuml,qalipsis-whitebox-scenario-execution,png]
----
skinparam componentStyle uml2

Runner *-left- "*" DirectedAcyclicGraph
DirectedAcyclicGraph "1" *-left- "*" Step: owns
Runner "Singleton" *-down-> "*" Minion
Step -left-> ExternalSystem

Minion *-right- MinionState: owns >
Minion "many" *-up- "any" DirectedAcyclicGraph: executes >
Minion -down-> "Singleton" MetricsReporter : saves\nmetric >

Step -down-> CorrelationProcessor : forwards\nrecord\nfor\ncorrelation

----

DirectedAcyclicGraph::
The https://en.wikipedia.org/wiki/Directed_acyclic_graph[DirectedAcyclicGraph] (or DAG) is a representation of consecutive or parallel vertices for the steps to perform locally on a single factory.
We support fan-in (one vertex has several direct ancestors) and fan-out (one vertex is direct ancestor of several ones).
However, we set a limitation on the construction of the DAGs: a vertex cannot be direct descendant of a transitive ancestor.
+
Since for technical and security reason some steps cannot be run anywhere (like reading a database or accessing a protected resource), the DAGs of a single minion can be distributed and executed on different factories.
A scenario is composed of at least one or more DAGs.
+
A DAG is not owned by a Minion, but its execution is.
Each vertex of a DAG has a unique ID used to route the data on the wire.

Minion::
The Minion executes the associated DAGs.
The DAGs execution are triggered by events or data coming from :
+
* either the runner (to start the minion),
* or a vertex of the same Minion running on a different factory.

MetricsReporter::
The Minion reports the execution flow metrics and results of the steps to the MetricsReporter, which is in charge of forwarding them to the head.

==== Factory - Correlation Processor (Whitebox)

.Whitebox Factory - Correlation Processor
[plantuml,qalipsis-whitebox-factory-correlation-processor,png]
----
skinparam componentStyle uml2

CorrelationProcessor ..> StepDataChannel : pushes\nrecord >
CorrelationProcessor "1" *-down- "1" ChannelsRegistry
CorrelationProcessor "1" *-down- "1" Cache
ChannelsRegistry "1" *-down- "*" StepDataChannel
StepDataChannel -left-* Step

SharedDataReader -> CorrelationProcessor
----

StepDataChannel::
Each step expecting remote data has a channel to which those data can be pushed when received from the wire.

SharedDataReader::
The SharedDataReader is a consumer of all the queues and topics relevant from all the minions of the current factory.
When a message is received, it is immediately forwarded to the correlation processor.

CorrelationProcessor::
The CorrelationProcessor routes the messages coming from the SharedDataReader to the relevant channel.
It uses metadata to find the channel to which the data have to be forwarder.
Those metadata are:
+
* Step ID (mandatory)
* Minion ID (optional)
* Correlation key generated using the data of the steps (optional)
+
At least one of the Minion ID or Correlation key is mandatory.
+
When using a Correlation key and no channel can be found (meaning the counterpart data with the same key was not yet generated), the record is kept in a cache and fetched later when required.
